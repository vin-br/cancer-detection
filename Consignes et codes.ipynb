{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3041e72",
   "metadata": {},
   "source": [
    "# Mise en situation - Détection cancer du sein \n",
    "\n",
    "Vous travaillez pour un clinique qui souhaite développer un modèle permettant de prédire la présence de cellules cancéreuse à partir des caractéristiques de cellules prélevées sur le sein à l'aide d'une biopsie à l'aiguille fine.  \n",
    "\n",
    "Pour cette mission, vous disposez du fichier de données `breast_cancer.csv`, de la documentation de ces données (https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data?resource=download) et du code d'un consultant avant vous, qui a eu le temps d'entraîner un premier modèle de prédiction.  \n",
    "\n",
    "Cependant, ce consultant n'a pas fait de travail préliminaire d'exploration des données et le client pense que le modèle pourrait être amélioré. Votre mission est donc :  \n",
    "\n",
    "- De présenter de manière extensive les données à votre client, par des statistiques descriptives et des visualisations adaptées.  \n",
    "- De proposer de nouveaux modèles de prédiction et de présenter les métriques d'évaluation adaptées pour justifier ou non des meilleurs résultats que le précédent.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e980ec73",
   "metadata": {},
   "source": [
    "# 1.  Analyse exploratoire des données  \n",
    "\n",
    "Pour cette partie, vous êtes libres des choix que vous ferez. Il faut cependant que votre notebook contienne :  \n",
    "- Affichage de quelques lignes du dataframe pour montrer sa structure.  \n",
    "- Présentation des différentes variables de la base et de leur type.  \n",
    "- Statistiques descriptives sur chacune des variables en fonction de leur type.  \n",
    "- Présenter des statistiques par diagnostic (bénin/malin) pour les variables, permettant de mettre en évidence l'aspect plus ou moins discriminant de certaines variables.  \n",
    "- Illustrer à l'aide de graphiques les variables les plus discriminantes en fonction du diagnostic (scatterplot avec différentes couleurs).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79861cfd",
   "metadata": {},
   "source": [
    "# 2. Évaluation d'un modèle  \n",
    "\n",
    "Pour cette partie, vous disposez du code du consultant précédent sur lequel vous pouvez vous appuyer. Votre mission :  \n",
    "- Expliquez les étapes du code réalisé :  \n",
    "        - En quoi consiste la standardisation des données? Pourquoi est-elle importante ici?   \n",
    "        - Expliquez à quoi sert le fait de séparer les données en entraînement et en test.  \n",
    "- Expliquez simplement comment fonctionne les arbres de décision.\n",
    "- Quelles sont les limites de la métrique choisie pour évaluer le modèle? Pour le même modèle, sortez d'autres métriques d'évaluation en les commentant (précision, recall, F1 score, matrice de confusion...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cea2ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9385964912280702\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "breast_cancer = pd.read_csv(\"data/breast_cancer.csv\")\n",
    "\n",
    "# On sépare les features du target \n",
    "features, target = breast_cancer.loc[:, 'radius_mean':'fractal_dimension_worst'], breast_cancer[\"diagnosis\"]\n",
    "\n",
    "# On split notre dataframe en 2\n",
    "feat_train, feat_test, target_train, target_test = train_test_split(\n",
    "    features, target,\n",
    "    test_size = 0.4)\n",
    "\n",
    "# On standardise  \n",
    "scaler = StandardScaler()\n",
    "feat_train = scaler.fit_transform(feat_train)\n",
    "feat_test = scaler.transform(feat_test)\n",
    "\n",
    "# On initalise le modèle \n",
    "tree_classif = tree.DecisionTreeClassifier()\n",
    "\n",
    "# On l'entraîne sur nos données d'entraînement\n",
    "tree_classif.fit(feat_train, target_train)\n",
    "\n",
    "# On l'utilise pour prédire sur les données de test\n",
    "predict_class = tree_classif.predict(feat_test)\n",
    "\n",
    "# On calcule l'accuracy du modèle  \n",
    "acc = accuracy_score(predict_class, target_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5fea03",
   "metadata": {},
   "source": [
    "# 3. Entraînement d'un modèle concurrent   \n",
    "En suivant la même logique, entraînez un modèle de classification avec la méthode des k plus proches voisins (ou k-nn). Expliquez comment il fonctionne. Sélectionnez le nombre de voisins qui vous donne le meilleur F1-score (en testant de 2 à 10 voisins) et comparez les performances de ce modèle avec le modèle précédent selon les différentes métriques.  \n",
    "\n",
    "__Bonus__ : Si vous avez le temps, entraînez un autre modèle de classification issu de `sklearn`, décrivez-le et présentez ses performances.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c392c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import neighbors, metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import model_selection\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "breast_cancer = pd.read_csv(\"data/breast_cancer.csv\")\n",
    "\n",
    "# On sépare les features du target \n",
    "features, target = breast_cancer.loc[:, 'radius_mean':'fractal_dimension_worst'], breast_cancer[\"diagnosis\"]\n",
    "\n",
    "# On split notre dataframe en 2\n",
    "feat_train, feat_test, target_train, target_test = train_test_split(\n",
    "    features, target,\n",
    "    test_size = 0.4)\n",
    "\n",
    "# On standardise\n",
    "scaler = StandardScaler()\n",
    "feat_train = scaler.fit_transform(feat_train)\n",
    "feat_test = scaler.transform(feat_test)\n",
    "\n",
    "\n",
    "# Fixer les valeurs des hyperparamètres à tester\n",
    "param_grid = {'n_neighbors':[2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
    "\n",
    "# Choisir un score à optimiser, ici l'accuracy (proportion de prédictions correctes)\n",
    "score = 'accuracy'\n",
    "\n",
    "# Créer un classifieur kNN avec recherche d'hyperparamètre par validation croisée\n",
    "clf = model_selection.GridSearchCV(neighbors.KNeighborsClassifier(), # un classifieur kNN\n",
    "    param_grid,     # hyperparamètres à tester\n",
    "    cv=5,\n",
    "    scoring=score)   # score à optimiser\n",
    "\n",
    "clf.fit(feat_train, target_train)\n",
    "\n",
    "\n",
    "# Afficher les performances correspondantes\n",
    "print(\"Résultats de la validation croisée:\")\n",
    "for mean, std, params in zip(clf.cvresults['mean_test_score'], # score moyen\n",
    "                                       clf.cvresults['std_test_score'],\n",
    "                                       clf.cvresults['params']):\n",
    "\n",
    "    print(\"{} = {:.3f} (+/-{:.03f}) for {}\".format(score,mean,std*2,params))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
